{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. 금융 뉴스 감성분석 개요"
      ],
      "metadata": {
        "id": "6l4flVmMaRzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 주식, 채권 등 다양한 금융상품을 투자할 때 금융지표, 기업의 정량 및 정성적 정보 등 다양하게 고려를 한다. 그러기 위해 기본적으로 금융뉴스를 확인해야한다. 뉴스가 어떤 정보를 가지고 있는지와 어떠한 뉘양스를 보이는지 파악해야 한다. 또한 금융 투자 초보자일 경우는 뉴스를 보고 이해하는 것도 힘들 수 있다. 그러기에 금융 뉴스의 뉘양스를 자연어 처리 딥러닝 빙식으로 감정분석을 하여 투자에 도움이 되는 금융 감정 분석 프로그램을 제작을 목표로 한다. "
      ],
      "metadata": {
        "id": "dw_u7I13a-ea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. import"
      ],
      "metadata": {
        "id": "QIi7fwZXclxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!set -x \\\n",
        "&& pip install konlpy \\\n",
        "&& curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh | bash -x "
      ],
      "metadata": {
        "id": "jf2jjUmpddB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from konlpy.tag import Mecab\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, Dense, GRU, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.optimizers import RMSprop\n",
        "from  keras.wrappers.scikit_learn  import KerasClassifier \n",
        "import  keras.backend  as  K"
      ],
      "metadata": {
        "id": "aPkJEZwmdfWS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 데이터 로드\n"
      ],
      "metadata": {
        "id": "zaZZOfXefD9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S8KCXryiTHn",
        "outputId": "84fcd5bb-f716-4e4d-ef01-bd1c13439014"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/finance_sentiment_corpus-main/finance_sentiment_corpus-main/finance_data.csv\")\n",
        "total_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "9VuPkndhiUZL",
        "outputId": "b3a2e4eb-5e1c-462e-b163-b90c6b3dc5ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     labels                                           sentence  \\\n",
              "0   neutral  According to Gran, the company has no plans to...   \n",
              "1   neutral  Technopolis plans to develop in stages an area...   \n",
              "2  negative  The international electronic industry company ...   \n",
              "3  positive  With the new production plant the company woul...   \n",
              "4  positive  According to the company's updated strategy fo...   \n",
              "5  positive  FINANCING OF ASPOCOMP'S GROWTH Aspocomp is agg...   \n",
              "6  positive  For the last quarter of 2010, Componenta's net...   \n",
              "7  positive  In the third quarter of 2010, net sales increa...   \n",
              "8  positive  Operating profit rose to EUR 13.1 mn from EUR ...   \n",
              "9  positive  Operating profit totalled EUR 21.1 mn, up from...   \n",
              "\n",
              "                                        kor_sentence  \n",
              "0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n",
              "1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n",
              "2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n",
              "3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n",
              "4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  \n",
              "5  ASPOCOMP의 성장기에 대한 자금 조달은 기술적으로 더 까다로운 HDI 인쇄 회...  \n",
              "6  2010년 4분기 Componenta의 순매출은 전년 동기의 7600만 유로에서 2...  \n",
              "7  2010년 3분기 순매출은 5.2%, 영업이익은 34.9% 증가한 23.5MN을 기...  \n",
              "8  영업이익은 2007년 해당 기간의 8.7 mn에서 13.1 mn으로 증가하여 순매출...  \n",
              "9  영업이익은 총 21.1 유로로 2007년 18.6 mn에서 증가하여 순매출의 9.7...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d314489-6332-480c-8520-62f515c6eabd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>sentence</th>\n",
              "      <th>kor_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>According to Gran, the company has no plans to...</td>\n",
              "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>According to the company's updated strategy fo...</td>\n",
              "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>positive</td>\n",
              "      <td>FINANCING OF ASPOCOMP'S GROWTH Aspocomp is agg...</td>\n",
              "      <td>ASPOCOMP의 성장기에 대한 자금 조달은 기술적으로 더 까다로운 HDI 인쇄 회...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>positive</td>\n",
              "      <td>For the last quarter of 2010, Componenta's net...</td>\n",
              "      <td>2010년 4분기 Componenta의 순매출은 전년 동기의 7600만 유로에서 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>positive</td>\n",
              "      <td>In the third quarter of 2010, net sales increa...</td>\n",
              "      <td>2010년 3분기 순매출은 5.2%, 영업이익은 34.9% 증가한 23.5MN을 기...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>positive</td>\n",
              "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
              "      <td>영업이익은 2007년 해당 기간의 8.7 mn에서 13.1 mn으로 증가하여 순매출...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>positive</td>\n",
              "      <td>Operating profit totalled EUR 21.1 mn, up from...</td>\n",
              "      <td>영업이익은 총 21.1 유로로 2007년 18.6 mn에서 증가하여 순매출의 9.7...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d314489-6332-480c-8520-62f515c6eabd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d314489-6332-480c-8520-62f515c6eabd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d314489-6332-480c-8520-62f515c6eabd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 데이터 전처리"
      ],
      "metadata": {
        "id": "PKy5cAWdjAn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_data = total_data.drop(['sentence'], axis=1)\n",
        "total_data.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "uoxBrF5IjFY_",
        "outputId": "35f36d46-d022-4d51-b886-ede14dae7653"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     labels                                       kor_sentence\n",
              "0   neutral  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...\n",
              "1   neutral  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...\n",
              "2  negative  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-971db414-5807-4470-ab24-78dfdc90012f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>kor_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-971db414-5807-4470-ab24-78dfdc90012f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-971db414-5807-4470-ab24-78dfdc90012f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-971db414-5807-4470-ab24-78dfdc90012f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data['labels'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UecY_i1rjmSD",
        "outputId": "cab1c961-a8a0-4718-80d4-952e321c29cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neutral', 'negative', 'positive'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data['labels'] = total_data['labels'].replace(['negative', 'neutral', 'positive'], [0, 1, 2]) \n",
        "total_data.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "wDXsxEwbk6Qg",
        "outputId": "9c6b17c0-9a4e-491b-9216-d036cb4d6b2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   labels                                       kor_sentence\n",
              "0       1  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...\n",
              "1       1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...\n",
              "2       0  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f3a5b86-99c9-4641-87d4-fa7c12bee6ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>kor_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f3a5b86-99c9-4641-87d4-fa7c12bee6ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f3a5b86-99c9-4641-87d4-fa7c12bee6ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f3a5b86-99c9-4641-87d4-fa7c12bee6ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복치 제거\n",
        "print(len(total_data))\n",
        "total_data.drop_duplicates(subset=['kor_sentence'], inplace=True)\n",
        "print(len(total_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c_1JPzEpTev",
        "outputId": "fd8c070d-f03a-482d-f18f-1d9e3bb9fa1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4846\n",
            "4827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "total_data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zyzF4-_rSni",
        "outputId": "e243d676-5079-4fdf-cc3f-e4c964e2cdca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "labels          0\n",
              "kor_sentence    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data['labels'].value_counts().plot(kind='bar')\n",
        "label_count = total_data.groupby('labels').size().reset_index(name='count')\n",
        "print(label_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "Sj33b2xTrzDF",
        "outputId": "f540e825-10c9-4ac8-ae02-8f3f7719fda8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   labels  count\n",
            "0       0    604\n",
            "1       1   2861\n",
            "2       2   1362\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 분리 -> validation 도 나누어서 kfold 교차검증 할 예정\n",
        "train_data, test_data = train_test_split(total_data, test_size=0.2, random_state=42)\n",
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpd7UMY_99NF",
        "outputId": "0532a9c9-30b6-424a-f53e-4b48d5990dca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3861\n",
            "966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 글자와 숫자만 남기고 제거 -> 영어랑 한국어 같이 있어도 되는지\n",
        "train_data['kor_sentence'] = train_data['kor_sentence'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9 ]\", \"\")\n",
        "print(len(train_data))\n",
        "print(train_data[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCvUDhv1_e7F",
        "outputId": "afc7ceef-c23d-47b2-8c25-894059327272"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3861\n",
            "      labels                                       kor_sentence\n",
            "4123       1                        올리페카 칼라스부오가 이사회 부회장으로 선출되었다\n",
            "2676       1  Savcor FACE를 Cencorp에 매각하면 받을 대가주 평가와 우세한 환율 등...\n",
            "536        1  이번 청약으로 TGK10에 대한 포텀의 지분은 주식과 의결권의 76를 약간 넘는 수...\n",
            "1909       1  패트릭 젬바는 또한 알스트롬의 혁신과 건강 안전 및 환경 HSEA 기능을 계속 담당...\n",
            "189        2  지분율은 542에 비해 609로 2007년 3분기 냉동식품 사업의 순매출액은 총 1...\n",
            "4628       1  4분기 말 현재 국내 통화 매출은 05퍼센트 감소한 반면 가입자 수는 1270만명 ...\n",
            "4187       0  EB는 2008년 11월 18일 증권거래소에서 JT를 발표했다 베르크비스트는 EB ...\n",
            "1751       2  헬싱키 톰슨 파이낸셜  코네는 사우디 아라비아 아랍에미리트 카타르에서 40mln 유...\n",
            "280        2        사노마 매거진 핀란드의 순매출액은 1318 mn에서 1401 mn으로 증가했다\n",
            "367        2                      핀란드의 매출은 39 증가했고 국제 성장률은 07였다\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-15263384a632>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  train_data['kor_sentence'] = train_data['kor_sentence'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9 ]\", \"\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['kor_sentence'] = test_data['kor_sentence'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9 ]\", \"\")\n",
        "print(len(test_data))\n",
        "print(test_data[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q666jNKWAmwl",
        "outputId": "6d244ef1-1149-4ed4-cf51-331fa6b4ba1b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "966\n",
            "      labels                                       kor_sentence\n",
            "590        2      YIT에 대한 고객들의 신뢰 증가는 아파트 매매가 가속화된 것으로 볼 수 있습니다\n",
            "2179       2    생산은 2010년 동안 멕시코와 헝가리를 포함한 엘코텍의 다른 지역으로 확대될 것이다\n",
            "917        2  바이살라는 또한 2009년의 2억5220만 유로에 비해 2010년에는 2억5320만...\n",
            "1484       2   우리는 스마트폰 기능 모바일 인터넷 서비스 개발 그리고 두 가지를 매끄러운 사용자...\n",
            "1702       1  핀란드의 배관 및 난방 시스템 공급 업체인 오노르는 2008년 8월 전사적인 비용 ...\n",
            "2626       1  이커머스 사이트와 플래그십은 지난해 미국에 설립된 자회사 마리멕코 북미리테일 LLC...\n",
            "1622       1  러시아 북서부 볼로그다 지역 셰크스나 지구에 대규모 목공시설을 2009년 착공해 2...\n",
            "1029       1  케이블비전 시스템즈 매디슨 스퀘어 가든은 매디슨 스퀘어 가든 뉴욕 레인저스 하키팀 ...\n",
            "4240       1                           신임 CEO가 선임될 때까지 선임은 유효하다\n",
            "4063       0  10월 UPM은 2007년 1억2000만 유로에 비해 3분기 순손실이 1억1000만...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-27ca7cfbcc23>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test_data['kor_sentence'] = test_data['kor_sentence'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9 ]\", \"\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 토큰화, 불용어 처리\n",
        "\n",
        "불용어 사전: '도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게'"
      ],
      "metadata": {
        "id": "hT-W2bY4-UVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']"
      ],
      "metadata": {
        "id": "wmNnGmCA-awH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mecab = Mecab()\n",
        "\n",
        "train_data['kor_sentence'] = train_data['kor_sentence'].apply(mecab.morphs)\n",
        "train_data['kor_sentence'] = train_data['kor_sentence'].apply(lambda x: [item for item in x if item not in stopwords])\n",
        "\n",
        "test_data['kor_sentence'] = test_data['kor_sentence'].apply(mecab.morphs)\n",
        "test_data['kor_sentence'] = test_data['kor_sentence'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "metadata": {
        "id": "y21KB0yY-oyK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['kor_sentence']\n",
        "X_test = test_data['kor_sentence']\n",
        "y_train = train_data['labels']\n",
        "y_test = test_data['labels']\n",
        "\n",
        "print(X_train[:2])\n",
        "print(y_train[:2])\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPLM6lCzBp1q",
        "outputId": "8d17c910-a0d2-43ef-fd2a-b64cfdc9157c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4123             [올리, 페카, 칼라스, 부오, 사회, 부회장, 으로, 선출, 되, 었]\n",
            "2676    [Savcor, FACE, Cencorp, 매각, 면, 받, 대, 가주, 평가, 우...\n",
            "Name: kor_sentence, dtype: object\n",
            "4123    1\n",
            "2676    1\n",
            "Name: labels, dtype: int64\n",
            "(3861,)\n",
            "(3861,)\n",
            "(966,)\n",
            "(966,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "R-SUKnQEDb24"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts = len(tokenizer.word_index) # 전체 단어 수"
      ],
      "metadata": {
        "id": "2e0UqhqSDegm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = word_counts + 2\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLuFm36XEOUK",
        "outputId": "ed86b42c-83bf-4c83-e617-791d26bef031"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "S33r8eslEPR5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[:3])\n",
        "print(X_test[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbrc9XOuET8k",
        "outputId": "c78f5ebe-fd9c-463d-d70d-d19259a407fb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1086, 1355, 3088, 1537, 277, 1211, 9, 1538, 16, 22], [2429, 3089, 1739, 172, 92, 175, 189, 3090, 750, 4487, 1539, 138, 3091, 9, 576, 1540, 3092, 250, 14, 24, 328, 227, 4488, 28, 7], [120, 577, 9, 2013, 75, 55, 178, 1356, 124, 63, 578, 2430, 798, 860, 339, 9, 4489]]\n",
            "[[485, 55, 88, 1995, 25, 1385, 3252, 8142, 169, 35, 7, 9, 654, 24, 4, 23], [68, 50, 2, 148, 1337, 2235, 70, 545, 195, 167, 130, 9, 490, 28, 7], [887, 659, 267, 150, 32, 2, 38, 53, 1, 13, 6, 114, 50, 2, 38, 53, 1, 13, 6, 48, 59, 28, 7, 9, 107, 471, 33]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 패딩"
      ],
      "metadata": {
        "id": "WIOq3UIhFrKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('문장 최대 길이 : ', max(len(l) for l in X_train))\n",
        "print('문장 평균 길이 : ', sum(map(len, X_train)) / len(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH6304DNFu2P",
        "outputId": "5c77af05-7985-4a0d-8c8f-a40bb4b75c10"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 최대 길이 :  55\n",
            "문장 평균 길이 :  18.656824656824657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.xlabel('Length of Samples')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "9Om6iMv-F07M",
        "outputId": "8dfb1fa3-92ea-48a0-9a00-7d12dc8c5ccf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 45\n",
        "\n",
        "# 패딩\n",
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)"
      ],
      "metadata": {
        "id": "1Z6peQ4JF736"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[:1])\n",
        "print(X_test[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC3Fx5HUURZB",
        "outputId": "b8fcab5b-f4d6-4e0b-a4cf-ca8a1a43d9c9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0 1086 1355 3088 1537  277 1211    9\n",
            "  1538   16   22]]\n",
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0  485   55   88 1995   25 1385 3252 8142  169   35    7    9  654\n",
            "    24    4   23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# softmax 적용을 해야해서 클래스를 나누어 주어야 함\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_test = to_categorical(y_test, 3)"
      ],
      "metadata": {
        "id": "k5ociujenSxX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. 모델링 (LSTM) "
      ],
      "metadata": {
        "id": "OkeG7IIFGJ7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "metadata": {
        "id": "0sNOK3ljEDIi"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(LSTM(128)) \n",
        "# model.add(BatchNormalization()) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation = 'relu')) \n",
        "# model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation = 'softmax'))\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_get_f1', mode='max', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "P1ACz5OfGS49"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=[get_f1]) \n",
        "\n",
        "model.summary()\n",
        "# recall, f1 등등 확인 -> 케라스 이용법 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfXQqKSBkU8w",
        "outputId": "77c4f6ec-6965-4912-dc60-46ecae0980ff"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 100)         937500    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               117248    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,063,199\n",
            "Trainable params: 1,063,199\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=100, callbacks=[es, mc], batch_size=60, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po0aIlzjkt0A",
        "outputId": "4f399831-ad37-46a3-b0ea-cfba15cc275a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.9458 - get_f1: 0.4044\n",
            "Epoch 1: val_get_f1 improved from -inf to 0.62242, saving model to best_model.h5\n",
            "52/52 [==============================] - 8s 19ms/step - loss: 0.9456 - get_f1: 0.4068 - val_loss: 0.8372 - val_get_f1: 0.6224\n",
            "Epoch 2/100\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.7390 - get_f1: 0.6414\n",
            "Epoch 2: val_get_f1 improved from 0.62242 to 0.68532, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.7297 - get_f1: 0.6434 - val_loss: 0.6939 - val_get_f1: 0.6853\n",
            "Epoch 3/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.4394 - get_f1: 0.8239\n",
            "Epoch 3: val_get_f1 improved from 0.68532 to 0.72741, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.4428 - get_f1: 0.8245 - val_loss: 0.6626 - val_get_f1: 0.7274\n",
            "Epoch 4/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.2029 - get_f1: 0.9359\n",
            "Epoch 4: val_get_f1 did not improve from 0.72741\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.2070 - get_f1: 0.9354 - val_loss: 0.8371 - val_get_f1: 0.6926\n",
            "Epoch 5/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.1037 - get_f1: 0.9705\n",
            "Epoch 5: val_get_f1 did not improve from 0.72741\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.1011 - get_f1: 0.9715 - val_loss: 1.0905 - val_get_f1: 0.7241\n",
            "Epoch 6/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0574 - get_f1: 0.9872\n",
            "Epoch 6: val_get_f1 improved from 0.72741 to 0.73350, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0574 - get_f1: 0.9866 - val_loss: 1.1790 - val_get_f1: 0.7335\n",
            "Epoch 7/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0335 - get_f1: 0.9920\n",
            "Epoch 7: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0347 - get_f1: 0.9910 - val_loss: 1.4288 - val_get_f1: 0.6908\n",
            "Epoch 8/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0228 - get_f1: 0.9936\n",
            "Epoch 8: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0237 - get_f1: 0.9934 - val_loss: 1.5829 - val_get_f1: 0.7135\n",
            "Epoch 9/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0184 - get_f1: 0.9964\n",
            "Epoch 9: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0176 - get_f1: 0.9966 - val_loss: 1.6576 - val_get_f1: 0.6985\n",
            "Epoch 10/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0144 - get_f1: 0.9964\n",
            "Epoch 10: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0143 - get_f1: 0.9965 - val_loss: 1.8845 - val_get_f1: 0.6978\n",
            "Epoch 11/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.1350 - get_f1: 0.9674\n",
            "Epoch 11: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.1369 - get_f1: 0.9665 - val_loss: 0.9480 - val_get_f1: 0.6838\n",
            "Epoch 12/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0471 - get_f1: 0.9870\n",
            "Epoch 12: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0447 - get_f1: 0.9880 - val_loss: 1.4381 - val_get_f1: 0.7252\n",
            "Epoch 13/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0097 - get_f1: 0.9975\n",
            "Epoch 13: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0095 - get_f1: 0.9974 - val_loss: 1.4733 - val_get_f1: 0.7234\n",
            "Epoch 14/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0077 - get_f1: 0.9983\n",
            "Epoch 14: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0086 - get_f1: 0.9974 - val_loss: 1.7511 - val_get_f1: 0.7297\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0070 - get_f1: 0.9981\n",
            "Epoch 15: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0070 - get_f1: 0.9981 - val_loss: 1.8757 - val_get_f1: 0.7076\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0047 - get_f1: 0.9992\n",
            "Epoch 16: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0047 - get_f1: 0.9992 - val_loss: 2.0849 - val_get_f1: 0.7305\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0060 - get_f1: 0.9978\n",
            "Epoch 17: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0060 - get_f1: 0.9978 - val_loss: 1.8662 - val_get_f1: 0.7079\n",
            "Epoch 18/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0052 - get_f1: 0.9988\n",
            "Epoch 18: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0049 - get_f1: 0.9989 - val_loss: 1.8217 - val_get_f1: 0.7165\n",
            "Epoch 19/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0036 - get_f1: 0.9986\n",
            "Epoch 19: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0037 - get_f1: 0.9987 - val_loss: 1.9578 - val_get_f1: 0.7159\n",
            "Epoch 20/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0058 - get_f1: 0.9992\n",
            "Epoch 20: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0058 - get_f1: 0.9992 - val_loss: 1.9538 - val_get_f1: 0.7173\n",
            "Epoch 21/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0021 - get_f1: 0.9995\n",
            "Epoch 21: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0027 - get_f1: 0.9992 - val_loss: 2.1515 - val_get_f1: 0.7111\n",
            "Epoch 22/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0022 - get_f1: 0.9993\n",
            "Epoch 22: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0021 - get_f1: 0.9994 - val_loss: 2.2452 - val_get_f1: 0.6993\n",
            "Epoch 23/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0023 - get_f1: 0.9991\n",
            "Epoch 23: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0022 - get_f1: 0.9992 - val_loss: 2.3562 - val_get_f1: 0.7104\n",
            "Epoch 24/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0022 - get_f1: 0.9989\n",
            "Epoch 24: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0024 - get_f1: 0.9987 - val_loss: 2.4051 - val_get_f1: 0.7112\n",
            "Epoch 25/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0024 - get_f1: 0.9991\n",
            "Epoch 25: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0023 - get_f1: 0.9992 - val_loss: 2.4087 - val_get_f1: 0.6962\n",
            "Epoch 26/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0084 - get_f1: 0.9965\n",
            "Epoch 26: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0081 - get_f1: 0.9966 - val_loss: 2.4712 - val_get_f1: 0.6957\n",
            "Epoch 27/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0130 - get_f1: 0.9958\n",
            "Epoch 27: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0129 - get_f1: 0.9957 - val_loss: 2.0406 - val_get_f1: 0.7247\n",
            "Epoch 28/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0105 - get_f1: 0.9976\n",
            "Epoch 28: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0109 - get_f1: 0.9971 - val_loss: 1.8397 - val_get_f1: 0.7253\n",
            "Epoch 29/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0622 - get_f1: 0.9822\n",
            "Epoch 29: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0592 - get_f1: 0.9830 - val_loss: 1.4202 - val_get_f1: 0.7233\n",
            "Epoch 30/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0117 - get_f1: 0.9959\n",
            "Epoch 30: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0140 - get_f1: 0.9958 - val_loss: 1.6916 - val_get_f1: 0.7098\n",
            "Epoch 31/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0063 - get_f1: 0.9986\n",
            "Epoch 31: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0075 - get_f1: 0.9981 - val_loss: 1.9020 - val_get_f1: 0.7041\n",
            "Epoch 32/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0149 - get_f1: 0.9965\n",
            "Epoch 32: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0140 - get_f1: 0.9968 - val_loss: 1.7635 - val_get_f1: 0.7044\n",
            "Epoch 33/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0043 - get_f1: 0.9986\n",
            "Epoch 33: val_get_f1 did not improve from 0.73350\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0041 - get_f1: 0.9987 - val_loss: 2.1127 - val_get_f1: 0.7058\n",
            "Epoch 33: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loaded_model = load_model('best_model.h5')\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_W-t7VLk2XO",
        "outputId": "9365e850-9ad3-4159-9202-fbb37b5e1ab1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 0s 4ms/step - loss: 2.0457 - get_f1: 0.7131\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.0456860065460205, 0.7130535244941711]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Fold Cross Validation\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((X_train, X_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "\n",
        "# 아래 부분에서 kfold가 아니라면 for문이 돌아갈필요가 없을것이다.\n",
        "\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model_k = Sequential()\n",
        "  model_k.add(Embedding(vocab_size, 100))\n",
        "  model_k.add(LSTM(128)) \n",
        "  model_k.add(Dropout(0.5))\n",
        "  model_k.add(Dense(64, activation = 'relu')) # 함수형 api 공부\n",
        "  model_k.add(Dropout(0.5))\n",
        "  model_k.add(Dense(3, activation = 'softmax'))\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
        "  mc = ModelCheckpoint('best_model.h5', monitor='val_get_f1', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "  # Compile the model\n",
        "  model_k.compile(optimizer = 'adam',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=[get_f1]) # recall, f1 등등 확인 -> 케라스 이용법 확인\n",
        "\n",
        "  #model.summary()\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model_k.fit(X_train, y_train, epochs=100, callbacks=[es, mc], batch_size=60, validation_split=0.2)\n",
        "\n",
        "  scores = model_k.evaluate(X_test, y_test)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6AGweseN8zt",
        "outputId": "3cccb8bb-809c-417c-eeef-d657ce5277ba"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.9643 - get_f1: 0.3703\n",
            "Epoch 1: val_get_f1 improved from -inf to 0.60514, saving model to best_model.h5\n",
            "52/52 [==============================] - 3s 19ms/step - loss: 0.9574 - get_f1: 0.3839 - val_loss: 0.8777 - val_get_f1: 0.6051\n",
            "Epoch 2/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.7468 - get_f1: 0.6313\n",
            "Epoch 2: val_get_f1 improved from 0.60514 to 0.65662, saving model to best_model.h5\n",
            "52/52 [==============================] - 1s 10ms/step - loss: 0.7379 - get_f1: 0.6407 - val_loss: 0.7086 - val_get_f1: 0.6566\n",
            "Epoch 3/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.4867 - get_f1: 0.7851\n",
            "Epoch 3: val_get_f1 improved from 0.65662 to 0.69501, saving model to best_model.h5\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4878 - get_f1: 0.7856 - val_loss: 0.7328 - val_get_f1: 0.6950\n",
            "Epoch 4/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.2465 - get_f1: 0.9213\n",
            "Epoch 4: val_get_f1 improved from 0.69501 to 0.72111, saving model to best_model.h5\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.2464 - get_f1: 0.9214 - val_loss: 0.8678 - val_get_f1: 0.7211\n",
            "Epoch 5/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.1162 - get_f1: 0.9681\n",
            "Epoch 5: val_get_f1 did not improve from 0.72111\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.1177 - get_f1: 0.9679 - val_loss: 0.8885 - val_get_f1: 0.7128\n",
            "Epoch 6/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0896 - get_f1: 0.9761\n",
            "Epoch 6: val_get_f1 improved from 0.72111 to 0.72804, saving model to best_model.h5\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0878 - get_f1: 0.9762 - val_loss: 1.3037 - val_get_f1: 0.7280\n",
            "Epoch 7/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0483 - get_f1: 0.9895\n",
            "Epoch 7: val_get_f1 did not improve from 0.72804\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0483 - get_f1: 0.9897 - val_loss: 1.4186 - val_get_f1: 0.6722\n",
            "Epoch 8/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0274 - get_f1: 0.9929\n",
            "Epoch 8: val_get_f1 did not improve from 0.72804\n",
            "52/52 [==============================] - 1s 9ms/step - loss: 0.0257 - get_f1: 0.9936 - val_loss: 1.5661 - val_get_f1: 0.7069\n",
            "Epoch 9/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0141 - get_f1: 0.9979\n",
            "Epoch 9: val_get_f1 did not improve from 0.72804\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0207 - get_f1: 0.9970 - val_loss: 1.6249 - val_get_f1: 0.7226\n",
            "Epoch 10/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0137 - get_f1: 0.9986\n",
            "Epoch 10: val_get_f1 did not improve from 0.72804\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0132 - get_f1: 0.9987 - val_loss: 1.6606 - val_get_f1: 0.6919\n",
            "Epoch 11/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0081 - get_f1: 0.9988\n",
            "Epoch 11: val_get_f1 did not improve from 0.72804\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0080 - get_f1: 0.9989 - val_loss: 1.8031 - val_get_f1: 0.7114\n",
            "Epoch 12/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0038 - get_f1: 0.9990\n",
            "Epoch 12: val_get_f1 did not improve from 0.72804\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0037 - get_f1: 0.9990 - val_loss: 2.0904 - val_get_f1: 0.6870\n",
            "Epoch 13/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0053 - get_f1: 0.9986\n",
            "Epoch 13: val_get_f1 did not improve from 0.72804\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0051 - get_f1: 0.9987 - val_loss: 2.0899 - val_get_f1: 0.7101\n",
            "Epoch 14/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0070 - get_f1: 0.9986\n",
            "Epoch 14: val_get_f1 did not improve from 0.72804\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0067 - get_f1: 0.9987 - val_loss: 2.0129 - val_get_f1: 0.6912\n",
            "Epoch 15/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0034 - get_f1: 0.9996\n",
            "Epoch 15: val_get_f1 did not improve from 0.72804\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0039 - get_f1: 0.9994 - val_loss: 2.1697 - val_get_f1: 0.7068\n",
            "Epoch 16/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0044 - get_f1: 0.9990\n",
            "Epoch 16: val_get_f1 did not improve from 0.72804\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0042 - get_f1: 0.9990 - val_loss: 2.0482 - val_get_f1: 0.7172\n",
            "Epoch 17/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0024 - get_f1: 0.9997\n",
            "Epoch 17: val_get_f1 did not improve from 0.72804\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0031 - get_f1: 0.9994 - val_loss: 2.2597 - val_get_f1: 0.7031\n",
            "Epoch 18/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0102 - get_f1: 0.9990\n",
            "Epoch 18: val_get_f1 did not improve from 0.72804\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0096 - get_f1: 0.9990 - val_loss: 2.1512 - val_get_f1: 0.7103\n",
            "Epoch 19/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0064 - get_f1: 0.9983\n",
            "Epoch 19: val_get_f1 improved from 0.72804 to 0.73674, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0086 - get_f1: 0.9981 - val_loss: 1.4894 - val_get_f1: 0.7367\n",
            "Epoch 20/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0244 - get_f1: 0.9949\n",
            "Epoch 20: val_get_f1 did not improve from 0.73674\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0227 - get_f1: 0.9954 - val_loss: 1.6421 - val_get_f1: 0.7114\n",
            "Epoch 21/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0133 - get_f1: 0.9972\n",
            "Epoch 21: val_get_f1 did not improve from 0.73674\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0137 - get_f1: 0.9971 - val_loss: 1.9816 - val_get_f1: 0.7069\n",
            "Epoch 22/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0197 - get_f1: 0.9938\n",
            "Epoch 22: val_get_f1 did not improve from 0.73674\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0189 - get_f1: 0.9939 - val_loss: 1.6926 - val_get_f1: 0.7014\n",
            "Epoch 23/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0281 - get_f1: 0.9915\n",
            "Epoch 23: val_get_f1 did not improve from 0.73674\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0288 - get_f1: 0.9910 - val_loss: 1.7915 - val_get_f1: 0.6775\n",
            "Epoch 24/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0366 - get_f1: 0.9910\n",
            "Epoch 24: val_get_f1 did not improve from 0.73674\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0367 - get_f1: 0.9904 - val_loss: 1.5871 - val_get_f1: 0.7242\n",
            "Epoch 25/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0265 - get_f1: 0.9939\n",
            "Epoch 25: val_get_f1 did not improve from 0.73674\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0267 - get_f1: 0.9939 - val_loss: 1.7561 - val_get_f1: 0.7282\n",
            "Epoch 26/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0214 - get_f1: 0.9962\n",
            "Epoch 26: val_get_f1 did not improve from 0.73674\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0217 - get_f1: 0.9958 - val_loss: 1.7879 - val_get_f1: 0.7156\n",
            "Epoch 27/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0162 - get_f1: 0.9967\n",
            "Epoch 27: val_get_f1 did not improve from 0.73674\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0162 - get_f1: 0.9963 - val_loss: 1.5805 - val_get_f1: 0.7220\n",
            "Epoch 28/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0156 - get_f1: 0.9976\n",
            "Epoch 28: val_get_f1 did not improve from 0.73674\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0155 - get_f1: 0.9974 - val_loss: 1.9623 - val_get_f1: 0.6887\n",
            "Epoch 29/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0034 - get_f1: 0.9989\n",
            "Epoch 29: val_get_f1 did not improve from 0.73674\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0032 - get_f1: 0.9990 - val_loss: 2.0738 - val_get_f1: 0.7002\n",
            "Epoch 30/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0028 - get_f1: 0.9993\n",
            "Epoch 30: val_get_f1 did not improve from 0.73674\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0026 - get_f1: 0.9994 - val_loss: 2.2458 - val_get_f1: 0.7170\n",
            "Epoch 31/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0034 - get_f1: 0.9995\n",
            "Epoch 31: val_get_f1 did not improve from 0.73674\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0040 - get_f1: 0.9992 - val_loss: 2.1666 - val_get_f1: 0.6958\n",
            "Epoch 32/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0022 - get_f1: 0.9990\n",
            "Epoch 32: val_get_f1 did not improve from 0.73674\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0020 - get_f1: 0.9990 - val_loss: 2.3993 - val_get_f1: 0.7167\n",
            "Epoch 32: early stopping\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 2.3967 - get_f1: 0.7278\n",
            "Score for fold 1: loss of 2.3966870307922363; get_f1 of 72.78225421905518%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/100\n",
            "50/52 [===========================>..] - ETA: 0s - loss: 0.9417 - get_f1: 0.4416\n",
            "Epoch 1: val_get_f1 improved from -inf to 0.62150, saving model to best_model.h5\n",
            "52/52 [==============================] - 3s 18ms/step - loss: 0.9387 - get_f1: 0.4456 - val_loss: 0.8018 - val_get_f1: 0.6215\n",
            "Epoch 2/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.6851 - get_f1: 0.6632\n",
            "Epoch 2: val_get_f1 improved from 0.62150 to 0.68058, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.6811 - get_f1: 0.6672 - val_loss: 0.6993 - val_get_f1: 0.6806\n",
            "Epoch 3/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.4164 - get_f1: 0.8295\n",
            "Epoch 3: val_get_f1 improved from 0.68058 to 0.72058, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.4120 - get_f1: 0.8321 - val_loss: 0.7024 - val_get_f1: 0.7206\n",
            "Epoch 4/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.2189 - get_f1: 0.9369\n",
            "Epoch 4: val_get_f1 improved from 0.72058 to 0.73828, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.2190 - get_f1: 0.9360 - val_loss: 0.8087 - val_get_f1: 0.7383\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0939 - get_f1: 0.9756\n",
            "Epoch 5: val_get_f1 did not improve from 0.73828\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0939 - get_f1: 0.9756 - val_loss: 1.2688 - val_get_f1: 0.7247\n",
            "Epoch 6/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0595 - get_f1: 0.9835\n",
            "Epoch 6: val_get_f1 improved from 0.73828 to 0.73851, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0585 - get_f1: 0.9841 - val_loss: 1.1506 - val_get_f1: 0.7385\n",
            "Epoch 7/100\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.0291 - get_f1: 0.9928\n",
            "Epoch 7: val_get_f1 did not improve from 0.73851\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0302 - get_f1: 0.9927 - val_loss: 1.4814 - val_get_f1: 0.7140\n",
            "Epoch 8/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0180 - get_f1: 0.9961\n",
            "Epoch 8: val_get_f1 did not improve from 0.73851\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0184 - get_f1: 0.9960 - val_loss: 1.4610 - val_get_f1: 0.7058\n",
            "Epoch 9/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0350 - get_f1: 0.9903\n",
            "Epoch 9: val_get_f1 improved from 0.73851 to 0.74254, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0338 - get_f1: 0.9905 - val_loss: 1.5878 - val_get_f1: 0.7425\n",
            "Epoch 10/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0236 - get_f1: 0.9948\n",
            "Epoch 10: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0259 - get_f1: 0.9947 - val_loss: 1.3469 - val_get_f1: 0.7338\n",
            "Epoch 11/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0324 - get_f1: 0.9901\n",
            "Epoch 11: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0309 - get_f1: 0.9909 - val_loss: 1.5506 - val_get_f1: 0.6884\n",
            "Epoch 12/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0199 - get_f1: 0.9944\n",
            "Epoch 12: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0194 - get_f1: 0.9943 - val_loss: 1.9685 - val_get_f1: 0.7255\n",
            "Epoch 13/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0204 - get_f1: 0.9956\n",
            "Epoch 13: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0195 - get_f1: 0.9957 - val_loss: 1.6979 - val_get_f1: 0.7176\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0090 - get_f1: 0.9982\n",
            "Epoch 14: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0090 - get_f1: 0.9982 - val_loss: 1.7259 - val_get_f1: 0.6970\n",
            "Epoch 15/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0166 - get_f1: 0.9954\n",
            "Epoch 15: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0160 - get_f1: 0.9955 - val_loss: 2.0151 - val_get_f1: 0.6740\n",
            "Epoch 16/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0138 - get_f1: 0.9956\n",
            "Epoch 16: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0144 - get_f1: 0.9958 - val_loss: 1.7874 - val_get_f1: 0.7124\n",
            "Epoch 17/100\n",
            "50/52 [===========================>..] - ETA: 0s - loss: 0.0096 - get_f1: 0.9980\n",
            "Epoch 17: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0094 - get_f1: 0.9981 - val_loss: 1.8108 - val_get_f1: 0.7364\n",
            "Epoch 18/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0066 - get_f1: 0.9984\n",
            "Epoch 18: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0062 - get_f1: 0.9986 - val_loss: 2.0531 - val_get_f1: 0.7135\n",
            "Epoch 19/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0033 - get_f1: 0.9991\n",
            "Epoch 19: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0038 - get_f1: 0.9989 - val_loss: 2.1805 - val_get_f1: 0.7031\n",
            "Epoch 20/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0022 - get_f1: 0.9993\n",
            "Epoch 20: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0030 - get_f1: 0.9990 - val_loss: 2.3809 - val_get_f1: 0.7168\n",
            "Epoch 21/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0039 - get_f1: 0.9989\n",
            "Epoch 21: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0037 - get_f1: 0.9990 - val_loss: 2.3470 - val_get_f1: 0.7019\n",
            "Epoch 22/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0037 - get_f1: 0.9993\n",
            "Epoch 22: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0035 - get_f1: 0.9994 - val_loss: 2.3265 - val_get_f1: 0.7126\n",
            "Epoch 23/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0035 - get_f1: 0.9993\n",
            "Epoch 23: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0081 - get_f1: 0.9990 - val_loss: 2.3180 - val_get_f1: 0.7090\n",
            "Epoch 24/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0040 - get_f1: 0.9990\n",
            "Epoch 24: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0039 - get_f1: 0.9990 - val_loss: 2.5137 - val_get_f1: 0.7125\n",
            "Epoch 25/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0047 - get_f1: 0.9989\n",
            "Epoch 25: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0046 - get_f1: 0.9990 - val_loss: 2.3968 - val_get_f1: 0.7062\n",
            "Epoch 26/100\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.0069 - get_f1: 0.9980\n",
            "Epoch 26: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0076 - get_f1: 0.9976 - val_loss: 2.1774 - val_get_f1: 0.7140\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0082 - get_f1: 0.9981\n",
            "Epoch 27: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0082 - get_f1: 0.9981 - val_loss: 2.1687 - val_get_f1: 0.7153\n",
            "Epoch 28/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0053 - get_f1: 0.9982\n",
            "Epoch 28: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0095 - get_f1: 0.9981 - val_loss: 2.1045 - val_get_f1: 0.7193\n",
            "Epoch 29/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0033 - get_f1: 0.9991\n",
            "Epoch 29: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0031 - get_f1: 0.9992 - val_loss: 2.3164 - val_get_f1: 0.7177\n",
            "Epoch 30/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0022 - get_f1: 0.9989\n",
            "Epoch 30: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0029 - get_f1: 0.9987 - val_loss: 2.4034 - val_get_f1: 0.7160\n",
            "Epoch 31/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0031 - get_f1: 0.9993\n",
            "Epoch 31: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0044 - get_f1: 0.9985 - val_loss: 2.3389 - val_get_f1: 0.7057\n",
            "Epoch 32/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0029 - get_f1: 0.9991\n",
            "Epoch 32: val_get_f1 did not improve from 0.74254\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0028 - get_f1: 0.9992 - val_loss: 2.4521 - val_get_f1: 0.7067\n",
            "Epoch 32: early stopping\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 2.4508 - get_f1: 0.7030\n",
            "Score for fold 2: loss of 2.4507803916931152; get_f1 of 70.29569149017334%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.9361 - get_f1: 0.4319\n",
            "Epoch 1: val_get_f1 improved from -inf to 0.62383, saving model to best_model.h5\n",
            "52/52 [==============================] - 3s 25ms/step - loss: 0.9295 - get_f1: 0.4477 - val_loss: 0.8073 - val_get_f1: 0.6238\n",
            "Epoch 2/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.6774 - get_f1: 0.6707\n",
            "Epoch 2: val_get_f1 improved from 0.62383 to 0.66150, saving model to best_model.h5\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.6759 - get_f1: 0.6740 - val_loss: 0.7274 - val_get_f1: 0.6615\n",
            "Epoch 3/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.4194 - get_f1: 0.8350\n",
            "Epoch 3: val_get_f1 improved from 0.66150 to 0.71535, saving model to best_model.h5\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4149 - get_f1: 0.8375 - val_loss: 0.7002 - val_get_f1: 0.7154\n",
            "Epoch 4/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.1959 - get_f1: 0.9404\n",
            "Epoch 4: val_get_f1 improved from 0.71535 to 0.73023, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.1935 - get_f1: 0.9403 - val_loss: 0.9753 - val_get_f1: 0.7302\n",
            "Epoch 5/100\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.0956 - get_f1: 0.9749\n",
            "Epoch 5: val_get_f1 did not improve from 0.73023\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0962 - get_f1: 0.9746 - val_loss: 1.0825 - val_get_f1: 0.7201\n",
            "Epoch 6/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0540 - get_f1: 0.9852\n",
            "Epoch 6: val_get_f1 did not improve from 0.73023\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0556 - get_f1: 0.9851 - val_loss: 1.2045 - val_get_f1: 0.7200\n",
            "Epoch 7/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0324 - get_f1: 0.9927\n",
            "Epoch 7: val_get_f1 improved from 0.73023 to 0.73244, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0328 - get_f1: 0.9928 - val_loss: 1.1700 - val_get_f1: 0.7324\n",
            "Epoch 8/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0425 - get_f1: 0.9867\n",
            "Epoch 8: val_get_f1 did not improve from 0.73244\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0404 - get_f1: 0.9878 - val_loss: 1.5201 - val_get_f1: 0.7318\n",
            "Epoch 9/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0137 - get_f1: 0.9970\n",
            "Epoch 9: val_get_f1 did not improve from 0.73244\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0145 - get_f1: 0.9966 - val_loss: 1.5171 - val_get_f1: 0.7186\n",
            "Epoch 10/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0239 - get_f1: 0.9940\n",
            "Epoch 10: val_get_f1 did not improve from 0.73244\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0276 - get_f1: 0.9935 - val_loss: 1.5875 - val_get_f1: 0.7228\n",
            "Epoch 11/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0115 - get_f1: 0.9972\n",
            "Epoch 11: val_get_f1 did not improve from 0.73244\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0137 - get_f1: 0.9968 - val_loss: 1.6269 - val_get_f1: 0.7116\n",
            "Epoch 12/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0128 - get_f1: 0.9979\n",
            "Epoch 12: val_get_f1 did not improve from 0.73244\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0126 - get_f1: 0.9981 - val_loss: 1.8979 - val_get_f1: 0.6436\n",
            "Epoch 13/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0153 - get_f1: 0.9966\n",
            "Epoch 13: val_get_f1 did not improve from 0.73244\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0146 - get_f1: 0.9966 - val_loss: 1.5446 - val_get_f1: 0.7270\n",
            "Epoch 14/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0302 - get_f1: 0.9922\n",
            "Epoch 14: val_get_f1 did not improve from 0.73244\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0295 - get_f1: 0.9925 - val_loss: 1.5770 - val_get_f1: 0.7075\n",
            "Epoch 15/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0224 - get_f1: 0.9938\n",
            "Epoch 15: val_get_f1 did not improve from 0.73244\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0221 - get_f1: 0.9932 - val_loss: 1.6921 - val_get_f1: 0.7060\n",
            "Epoch 16/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0202 - get_f1: 0.9954\n",
            "Epoch 16: val_get_f1 improved from 0.73244 to 0.73606, saving model to best_model.h5\n",
            "52/52 [==============================] - 1s 10ms/step - loss: 0.0196 - get_f1: 0.9953 - val_loss: 1.7585 - val_get_f1: 0.7361\n",
            "Epoch 17/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0061 - get_f1: 0.9990\n",
            "Epoch 17: val_get_f1 did not improve from 0.73606\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0059 - get_f1: 0.9990 - val_loss: 1.8812 - val_get_f1: 0.7197\n",
            "Epoch 18/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0045 - get_f1: 0.9989\n",
            "Epoch 18: val_get_f1 did not improve from 0.73606\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0070 - get_f1: 0.9987 - val_loss: 1.9749 - val_get_f1: 0.7177\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0040 - get_f1: 0.9990\n",
            "Epoch 19: val_get_f1 did not improve from 0.73606\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0040 - get_f1: 0.9990 - val_loss: 1.9248 - val_get_f1: 0.7195\n",
            "Epoch 20/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0037 - get_f1: 0.9991\n",
            "Epoch 20: val_get_f1 did not improve from 0.73606\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0034 - get_f1: 0.9992 - val_loss: 2.0353 - val_get_f1: 0.7351\n",
            "Epoch 21/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0047 - get_f1: 0.9993\n",
            "Epoch 21: val_get_f1 improved from 0.73606 to 0.73811, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0068 - get_f1: 0.9990 - val_loss: 1.9642 - val_get_f1: 0.7381\n",
            "Epoch 22/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0034 - get_f1: 0.9991\n",
            "Epoch 22: val_get_f1 did not improve from 0.73811\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0032 - get_f1: 0.9992 - val_loss: 2.1118 - val_get_f1: 0.7117\n",
            "Epoch 23/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0020 - get_f1: 0.9996\n",
            "Epoch 23: val_get_f1 did not improve from 0.73811\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0021 - get_f1: 0.9995 - val_loss: 2.1636 - val_get_f1: 0.7316\n",
            "Epoch 24/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0052 - get_f1: 0.9989\n",
            "Epoch 24: val_get_f1 did not improve from 0.73811\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0048 - get_f1: 0.9990 - val_loss: 2.0844 - val_get_f1: 0.7106\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0055 - get_f1: 0.9989\n",
            "Epoch 25: val_get_f1 improved from 0.73811 to 0.73980, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0055 - get_f1: 0.9989 - val_loss: 2.0404 - val_get_f1: 0.7398\n",
            "Epoch 26/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0033 - get_f1: 0.9989\n",
            "Epoch 26: val_get_f1 did not improve from 0.73980\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0031 - get_f1: 0.9990 - val_loss: 2.4167 - val_get_f1: 0.7216\n",
            "Epoch 27/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0217 - get_f1: 0.9937\n",
            "Epoch 27: val_get_f1 did not improve from 0.73980\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0220 - get_f1: 0.9933 - val_loss: 1.7214 - val_get_f1: 0.6769\n",
            "Epoch 28/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0167 - get_f1: 0.9944\n",
            "Epoch 28: val_get_f1 did not improve from 0.73980\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0174 - get_f1: 0.9941 - val_loss: 1.9627 - val_get_f1: 0.6986\n",
            "Epoch 29/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0344 - get_f1: 0.9915\n",
            "Epoch 29: val_get_f1 did not improve from 0.73980\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0330 - get_f1: 0.9915 - val_loss: 1.7773 - val_get_f1: 0.7072\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0113 - get_f1: 0.9968\n",
            "Epoch 30: val_get_f1 did not improve from 0.73980\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0113 - get_f1: 0.9968 - val_loss: 2.0310 - val_get_f1: 0.6768\n",
            "Epoch 31/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0127 - get_f1: 0.9958\n",
            "Epoch 31: val_get_f1 did not improve from 0.73980\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0145 - get_f1: 0.9960 - val_loss: 2.0595 - val_get_f1: 0.6806\n",
            "Epoch 32/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0066 - get_f1: 0.9988\n",
            "Epoch 32: val_get_f1 did not improve from 0.73980\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0063 - get_f1: 0.9989 - val_loss: 2.5112 - val_get_f1: 0.6858\n",
            "Epoch 33/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0015 - get_f1: 0.9996\n",
            "Epoch 33: val_get_f1 did not improve from 0.73980\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0026 - get_f1: 0.9990 - val_loss: 2.5251 - val_get_f1: 0.7011\n",
            "Epoch 33: early stopping\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 2.4346 - get_f1: 0.7128\n",
            "Score for fold 3: loss of 2.434570550918579; get_f1 of 71.27975225448608%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.9427 - get_f1: 0.4284\n",
            "Epoch 1: val_get_f1 improved from -inf to 0.60303, saving model to best_model.h5\n",
            "52/52 [==============================] - 3s 18ms/step - loss: 0.9404 - get_f1: 0.4338 - val_loss: 0.8377 - val_get_f1: 0.6030\n",
            "Epoch 2/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.7104 - get_f1: 0.6556\n",
            "Epoch 2: val_get_f1 improved from 0.60303 to 0.68711, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.6983 - get_f1: 0.6640 - val_loss: 0.6917 - val_get_f1: 0.6871\n",
            "Epoch 3/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.4256 - get_f1: 0.8310\n",
            "Epoch 3: val_get_f1 improved from 0.68711 to 0.71697, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.4273 - get_f1: 0.8310 - val_loss: 0.6930 - val_get_f1: 0.7170\n",
            "Epoch 4/100\n",
            "50/52 [===========================>..] - ETA: 0s - loss: 0.1964 - get_f1: 0.9375\n",
            "Epoch 4: val_get_f1 did not improve from 0.71697\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.1955 - get_f1: 0.9386 - val_loss: 0.8650 - val_get_f1: 0.7048\n",
            "Epoch 5/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0866 - get_f1: 0.9756\n",
            "Epoch 5: val_get_f1 did not improve from 0.71697\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0879 - get_f1: 0.9753 - val_loss: 1.0238 - val_get_f1: 0.7060\n",
            "Epoch 6/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0808 - get_f1: 0.9782\n",
            "Epoch 6: val_get_f1 did not improve from 0.71697\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0803 - get_f1: 0.9786 - val_loss: 1.1883 - val_get_f1: 0.7164\n",
            "Epoch 7/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0534 - get_f1: 0.9855\n",
            "Epoch 7: val_get_f1 did not improve from 0.71697\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0507 - get_f1: 0.9867 - val_loss: 1.2271 - val_get_f1: 0.7126\n",
            "Epoch 8/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0203 - get_f1: 0.9951\n",
            "Epoch 8: val_get_f1 did not improve from 0.71697\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0205 - get_f1: 0.9947 - val_loss: 1.6084 - val_get_f1: 0.7158\n",
            "Epoch 9/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0182 - get_f1: 0.9953\n",
            "Epoch 9: val_get_f1 improved from 0.71697 to 0.72010, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0178 - get_f1: 0.9953 - val_loss: 1.6472 - val_get_f1: 0.7201\n",
            "Epoch 10/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0158 - get_f1: 0.9972\n",
            "Epoch 10: val_get_f1 did not improve from 0.72010\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0180 - get_f1: 0.9971 - val_loss: 1.6534 - val_get_f1: 0.7091\n",
            "Epoch 11/100\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.0097 - get_f1: 0.9985\n",
            "Epoch 11: val_get_f1 improved from 0.72010 to 0.73629, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0101 - get_f1: 0.9981 - val_loss: 1.7075 - val_get_f1: 0.7363\n",
            "Epoch 12/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0085 - get_f1: 0.9983\n",
            "Epoch 12: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0080 - get_f1: 0.9984 - val_loss: 1.9237 - val_get_f1: 0.7210\n",
            "Epoch 13/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0063 - get_f1: 0.9982\n",
            "Epoch 13: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0069 - get_f1: 0.9979 - val_loss: 1.6165 - val_get_f1: 0.7236\n",
            "Epoch 14/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0106 - get_f1: 0.9986\n",
            "Epoch 14: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0102 - get_f1: 0.9987 - val_loss: 1.7562 - val_get_f1: 0.7146\n",
            "Epoch 15/100\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.0037 - get_f1: 0.9996\n",
            "Epoch 15: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0044 - get_f1: 0.9994 - val_loss: 2.0297 - val_get_f1: 0.7207\n",
            "Epoch 16/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0056 - get_f1: 0.9984\n",
            "Epoch 16: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0053 - get_f1: 0.9986 - val_loss: 2.2604 - val_get_f1: 0.7238\n",
            "Epoch 17/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0047 - get_f1: 0.9993\n",
            "Epoch 17: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0044 - get_f1: 0.9994 - val_loss: 2.3208 - val_get_f1: 0.7305\n",
            "Epoch 18/100\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.0054 - get_f1: 0.9989\n",
            "Epoch 18: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0052 - get_f1: 0.9987 - val_loss: 2.2642 - val_get_f1: 0.7317\n",
            "Epoch 19/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0068 - get_f1: 0.9982\n",
            "Epoch 19: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0063 - get_f1: 0.9984 - val_loss: 2.2987 - val_get_f1: 0.7187\n",
            "Epoch 20/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0029 - get_f1: 0.9993\n",
            "Epoch 20: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0029 - get_f1: 0.9994 - val_loss: 2.2110 - val_get_f1: 0.7219\n",
            "Epoch 21/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0245 - get_f1: 0.9922\n",
            "Epoch 21: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0331 - get_f1: 0.9899 - val_loss: 1.5446 - val_get_f1: 0.6997\n",
            "Epoch 22/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0420 - get_f1: 0.9893\n",
            "Epoch 22: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0441 - get_f1: 0.9884 - val_loss: 2.0005 - val_get_f1: 0.6832\n",
            "Epoch 23/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0305 - get_f1: 0.9937\n",
            "Epoch 23: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0364 - get_f1: 0.9934 - val_loss: 1.4733 - val_get_f1: 0.7087\n",
            "Epoch 24/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0167 - get_f1: 0.9949\n",
            "Epoch 24: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0158 - get_f1: 0.9952 - val_loss: 1.8807 - val_get_f1: 0.7157\n",
            "Epoch 25/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0115 - get_f1: 0.9981\n",
            "Epoch 25: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0111 - get_f1: 0.9982 - val_loss: 1.8528 - val_get_f1: 0.6835\n",
            "Epoch 26/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0162 - get_f1: 0.9957\n",
            "Epoch 26: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0160 - get_f1: 0.9958 - val_loss: 1.8574 - val_get_f1: 0.6941\n",
            "Epoch 27/100\n",
            "50/52 [===========================>..] - ETA: 0s - loss: 0.0219 - get_f1: 0.9927\n",
            "Epoch 27: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0214 - get_f1: 0.9929 - val_loss: 1.7410 - val_get_f1: 0.7164\n",
            "Epoch 28/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0070 - get_f1: 0.9986\n",
            "Epoch 28: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0076 - get_f1: 0.9981 - val_loss: 2.0469 - val_get_f1: 0.7213\n",
            "Epoch 29/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0045 - get_f1: 0.9984\n",
            "Epoch 29: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0044 - get_f1: 0.9984 - val_loss: 2.2004 - val_get_f1: 0.7108\n",
            "Epoch 30/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0051 - get_f1: 0.9989\n",
            "Epoch 30: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0047 - get_f1: 0.9990 - val_loss: 2.1834 - val_get_f1: 0.6906\n",
            "Epoch 31/100\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.0040 - get_f1: 0.9989\n",
            "Epoch 31: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0059 - get_f1: 0.9984 - val_loss: 2.1471 - val_get_f1: 0.7089\n",
            "Epoch 32/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0114 - get_f1: 0.9971\n",
            "Epoch 32: val_get_f1 did not improve from 0.73629\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0128 - get_f1: 0.9962 - val_loss: 1.8880 - val_get_f1: 0.6917\n",
            "Epoch 32: early stopping\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 1.8084 - get_f1: 0.7090\n",
            "Score for fold 4: loss of 1.8083535432815552; get_f1 of 70.89676260948181%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.9500 - get_f1: 0.4171\n",
            "Epoch 1: val_get_f1 improved from -inf to 0.62358, saving model to best_model.h5\n",
            "52/52 [==============================] - 3s 19ms/step - loss: 0.9423 - get_f1: 0.4340 - val_loss: 0.8284 - val_get_f1: 0.6236\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.7038 - get_f1: 0.6566\n",
            "Epoch 2: val_get_f1 improved from 0.62358 to 0.69272, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.7038 - get_f1: 0.6566 - val_loss: 0.6955 - val_get_f1: 0.6927\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.4266 - get_f1: 0.8278\n",
            "Epoch 3: val_get_f1 improved from 0.69272 to 0.70484, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.4266 - get_f1: 0.8278 - val_loss: 0.7051 - val_get_f1: 0.7048\n",
            "Epoch 4/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.2006 - get_f1: 0.9358\n",
            "Epoch 4: val_get_f1 improved from 0.70484 to 0.72732, saving model to best_model.h5\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.1999 - get_f1: 0.9360 - val_loss: 0.8716 - val_get_f1: 0.7273\n",
            "Epoch 5/100\n",
            "50/52 [===========================>..] - ETA: 0s - loss: 0.0837 - get_f1: 0.9752\n",
            "Epoch 5: val_get_f1 did not improve from 0.72732\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0840 - get_f1: 0.9750 - val_loss: 0.9778 - val_get_f1: 0.7087\n",
            "Epoch 6/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0528 - get_f1: 0.9861\n",
            "Epoch 6: val_get_f1 did not improve from 0.72732\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0518 - get_f1: 0.9868 - val_loss: 1.4652 - val_get_f1: 0.7147\n",
            "Epoch 7/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0369 - get_f1: 0.9910\n",
            "Epoch 7: val_get_f1 improved from 0.72732 to 0.73700, saving model to best_model.h5\n",
            "52/52 [==============================] - 1s 10ms/step - loss: 0.0379 - get_f1: 0.9905 - val_loss: 1.2444 - val_get_f1: 0.7370\n",
            "Epoch 8/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0225 - get_f1: 0.9966\n",
            "Epoch 8: val_get_f1 did not improve from 0.73700\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0223 - get_f1: 0.9966 - val_loss: 1.7682 - val_get_f1: 0.7314\n",
            "Epoch 9/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0175 - get_f1: 0.9961\n",
            "Epoch 9: val_get_f1 did not improve from 0.73700\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0203 - get_f1: 0.9958 - val_loss: 1.5881 - val_get_f1: 0.7232\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0191 - get_f1: 0.9965\n",
            "Epoch 10: val_get_f1 improved from 0.73700 to 0.73838, saving model to best_model.h5\n",
            "52/52 [==============================] - 1s 10ms/step - loss: 0.0191 - get_f1: 0.9965 - val_loss: 1.4732 - val_get_f1: 0.7384\n",
            "Epoch 11/100\n",
            "50/52 [===========================>..] - ETA: 0s - loss: 0.0089 - get_f1: 0.9990\n",
            "Epoch 11: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0087 - get_f1: 0.9990 - val_loss: 1.6377 - val_get_f1: 0.7133\n",
            "Epoch 12/100\n",
            "45/52 [========================>.....] - ETA: 0s - loss: 0.0110 - get_f1: 0.9981\n",
            "Epoch 12: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 1s 11ms/step - loss: 0.0120 - get_f1: 0.9969 - val_loss: 1.8169 - val_get_f1: 0.7010\n",
            "Epoch 13/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0399 - get_f1: 0.9894\n",
            "Epoch 13: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0403 - get_f1: 0.9889 - val_loss: 1.5051 - val_get_f1: 0.6916\n",
            "Epoch 14/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0198 - get_f1: 0.9952\n",
            "Epoch 14: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0198 - get_f1: 0.9948 - val_loss: 1.7244 - val_get_f1: 0.7260\n",
            "Epoch 15/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0162 - get_f1: 0.9971\n",
            "Epoch 15: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0161 - get_f1: 0.9971 - val_loss: 1.6566 - val_get_f1: 0.7240\n",
            "Epoch 16/100\n",
            "50/52 [===========================>..] - ETA: 0s - loss: 0.0321 - get_f1: 0.9917\n",
            "Epoch 16: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0315 - get_f1: 0.9920 - val_loss: 1.7257 - val_get_f1: 0.6939\n",
            "Epoch 17/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0281 - get_f1: 0.9921\n",
            "Epoch 17: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0279 - get_f1: 0.9923 - val_loss: 1.7248 - val_get_f1: 0.7127\n",
            "Epoch 18/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0178 - get_f1: 0.9972\n",
            "Epoch 18: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0181 - get_f1: 0.9966 - val_loss: 1.7061 - val_get_f1: 0.6967\n",
            "Epoch 19/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0116 - get_f1: 0.9961\n",
            "Epoch 19: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0112 - get_f1: 0.9963 - val_loss: 1.8510 - val_get_f1: 0.6936\n",
            "Epoch 20/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0106 - get_f1: 0.9966\n",
            "Epoch 20: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0105 - get_f1: 0.9966 - val_loss: 2.1140 - val_get_f1: 0.6902\n",
            "Epoch 21/100\n",
            "46/52 [=========================>....] - ETA: 0s - loss: 0.0159 - get_f1: 0.9949\n",
            "Epoch 21: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0167 - get_f1: 0.9949 - val_loss: 1.5309 - val_get_f1: 0.7232\n",
            "Epoch 22/100\n",
            "50/52 [===========================>..] - ETA: 0s - loss: 0.0092 - get_f1: 0.9978\n",
            "Epoch 22: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0090 - get_f1: 0.9979 - val_loss: 1.8920 - val_get_f1: 0.7113\n",
            "Epoch 23/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0037 - get_f1: 0.9993\n",
            "Epoch 23: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0036 - get_f1: 0.9994 - val_loss: 2.0455 - val_get_f1: 0.7060\n",
            "Epoch 24/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0042 - get_f1: 0.9991\n",
            "Epoch 24: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0054 - get_f1: 0.9989 - val_loss: 2.1503 - val_get_f1: 0.7085\n",
            "Epoch 25/100\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0052 - get_f1: 0.9990\n",
            "Epoch 25: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0050 - get_f1: 0.9990 - val_loss: 2.0486 - val_get_f1: 0.7037\n",
            "Epoch 26/100\n",
            "48/52 [==========================>...] - ETA: 0s - loss: 0.0043 - get_f1: 0.9988\n",
            "Epoch 26: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0040 - get_f1: 0.9989 - val_loss: 2.0923 - val_get_f1: 0.7093\n",
            "Epoch 27/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0042 - get_f1: 0.9990\n",
            "Epoch 27: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0041 - get_f1: 0.9990 - val_loss: 2.2288 - val_get_f1: 0.7027\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0037 - get_f1: 0.9990\n",
            "Epoch 28: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0037 - get_f1: 0.9990 - val_loss: 2.3244 - val_get_f1: 0.7010\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0038 - get_f1: 0.9990\n",
            "Epoch 29: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0038 - get_f1: 0.9990 - val_loss: 2.1915 - val_get_f1: 0.7144\n",
            "Epoch 30/100\n",
            "47/52 [==========================>...] - ETA: 0s - loss: 0.0033 - get_f1: 0.9989\n",
            "Epoch 30: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0031 - get_f1: 0.9990 - val_loss: 2.2097 - val_get_f1: 0.7168\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0019 - get_f1: 0.9994\n",
            "Epoch 31: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0019 - get_f1: 0.9994 - val_loss: 2.3814 - val_get_f1: 0.7228\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.0034 - get_f1: 0.9990\n",
            "Epoch 32: val_get_f1 did not improve from 0.73838\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0034 - get_f1: 0.9990 - val_loss: 2.2966 - val_get_f1: 0.7079\n",
            "Epoch 32: early stopping\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 2.3977 - get_f1: 0.7100\n",
            "Score for fold 5: loss of 2.397738456726074; get_f1 of 70.99813222885132%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_pred(new_sentence) :\n",
        "    new_token = [word for word in mecab.morphs(new_sentence) if not word in stopwords]\n",
        "    new_sequences = tokenizer.texts_to_sequences([new_token])\n",
        "    new_pad = pad_sequences(new_sequences, maxlen = max_len)\n",
        "    #print(new_pad)\n",
        "    score = model.predict(new_pad)\n",
        "    #print(score)\n",
        "    #print(np.argmax(score))\n",
        "    max_score = score[0][np.argmax(score)]\n",
        "\n",
        "    if np.argmax(score) == 0 :\n",
        "        print(f'기사 제목 : {new_sentence} -> 부정({(max_score*100):.2f}%)')\n",
        "    elif np.argmax(score) == 1 :\n",
        "        print(f'기사 제목 : {new_sentence} -> 중립({(max_score*100):.2f}%)')\n",
        "    else :\n",
        "        print(f'기사 제목 : {new_sentence} -> 긍정({(max_score*100):.2f}%)')"
      ],
      "metadata": {
        "id": "44YkvU-XnvDl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_pred('이번주 방향성 없는 코스피…시장은 재차 숨고르기')\n",
        "sentiment_pred('올해 마지막 FOMC 앞두고 블랙아웃 진입…피봇 기대감 여전')\n",
        "sentiment_pred('올해 삼성전자 임원 자사주 121억원 매입…주가부양 노력')\n",
        "sentiment_pred('세일즈포스, 3분기 실적 컨센 상회…계약 반등 시점은 불확실')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwKZMmqYn2xv",
        "outputId": "086b94c2-32eb-455d-986f-95a9c21c771b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "기사 제목 : 이번주 방향성 없는 코스피…시장은 재차 숨고르기 -> 중립(97.23%)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "기사 제목 : 올해 마지막 FOMC 앞두고 블랙아웃 진입…피봇 기대감 여전 -> 중립(97.80%)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "기사 제목 : 올해 삼성전자 임원 자사주 121억원 매입…주가부양 노력 -> 긍정(100.00%)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "기사 제목 : 세일즈포스, 3분기 실적 컨센 상회…계약 반등 시점은 불확실 -> 부정(87.30%)\n"
          ]
        }
      ]
    }
  ]
}